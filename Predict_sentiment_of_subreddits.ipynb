{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict sentiment of subreddits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1h0upfHzSozBaxfHyFoSjlvg3uAxUdUxp",
      "authorship_tag": "ABX9TyPnvUlvoGApsc5t8JJw8gih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rathore25/Reddit-Sentiment-Pre-Post-Covid/blob/main/Predict_sentiment_of_subreddits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pedfYrhEoUbb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import codecs\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXdkcgWeodE5"
      },
      "source": [
        "project_dir = '/content/drive/MyDrive/NEU/6120/Final Project/'\n",
        "subreddits  = ['boston','losangeles','texas','mentalhealth','depression']\n",
        "periods     = [\"Jan'19\",\"Feb'19\",\"Mar'19\",\"Apr'19\",\"May'19\",\"Jun'19\",\"Jul'19\",\"Aug'19\",\"Sep'19\",\"Oct'19\",\"Nov'19\",\"Dec'19\",\n",
        "               \"Jan'20\",\"Feb'20\",\"Mar'20\",\"Apr'20\",\"May'20\",\"Jun'20\",\"Jul'20\",\"Aug'20\",\"Sep'20\",\"Oct'20\",\"Nov'20\",\"Dec'20\",\n",
        "               \"Jan'21\",\"Feb'21\",\"Mar'21\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RINMFeTgonR8"
      },
      "source": [
        "dfs = {}\n",
        "for subreddit in subreddits:\n",
        "  dfs[subreddit] = pd.read_csv('{0}{1}.csv'.format(project_dir,subreddit), encoding = 'utf-8-sig')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iVuwWuxqai5"
      },
      "source": [
        "#model_train_false_32k\n",
        "model_path  = project_dir + 'train_false_32k'\n",
        "model       = keras.models.load_model(model_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtJuqhl7rDP1",
        "outputId": "804a9907-6365-4c76-d9da-d0ee23f1a781"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_2 (KerasLayer)   (None, 512)               147354880 \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 147,502,721\n",
            "Trainable params: 147,502,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsGW9CnurjEl"
      },
      "source": [
        "def getPredictions(df, model):\n",
        "  print(df.shape)\n",
        "  batch_size  = 1000\n",
        "  length      = len(df)\n",
        "  batches     = length//1000 + 1\n",
        "  all_texts   = list(df['body'].values)\n",
        "  predictions = []\n",
        "  start_time  = time.time()\n",
        "\n",
        "  for i in range(batches):\n",
        "    print(\"Batch:\", i)\n",
        "    start_index = i * batch_size\n",
        "    end_index   = min(start_index+batch_size,length)\n",
        "    curr_batch  = all_texts[start_index:end_index]\n",
        "    curr_pred   = model.predict(curr_batch)\n",
        "    curr_pred   = np.squeeze(curr_pred)\n",
        "    predictions.extend(curr_pred)\n",
        "  \n",
        "  print(\"Time taken:\", time.time() - start_time)\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgQsJSbduZKn"
      },
      "source": [
        "for subreddit in subreddits:\n",
        "  print(subreddit)\n",
        "  ypred                         = getPredictions(dfs[subreddit], model)\n",
        "  dfs[subreddit]['prediction']  = ypred\n",
        "  file_path                     = '{0}{1}_pred.csv'.format(project_dir,subreddit)\n",
        "  \n",
        "  with open(file_path, 'w', encoding = 'utf-8-sig') as file:\n",
        "    file.write(dfs[subreddit].to_csv(index=False,encoding = 'utf-8-sig'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}