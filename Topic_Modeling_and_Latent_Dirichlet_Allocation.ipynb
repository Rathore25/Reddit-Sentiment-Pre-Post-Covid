{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modeling and Latent Dirichlet Allocation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11DwdTnbUni1acWYMJXMQ2WjbEJq5pBeH",
      "authorship_tag": "ABX9TyNA4ugNZzqUG15ZdCpNuuQh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rathore25/Reddit-Sentiment-Pre-Post-Covid/blob/main/Topic_Modeling_and_Latent_Dirichlet_Allocation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83C-IsIYFxwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9804579a-949d-48e1-c981-4c72baafc817"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "nltk.download('wordnet')      #download if using this module for the first time\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')    #download if using this module for the first time\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "#For Gensim\n",
        "import gensim\n",
        "import string\n",
        "from gensim import corpora\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IIEqkupGniB"
      },
      "source": [
        "project_dir = '/content/drive/MyDrive/NEU/6120/Final Project/'\n",
        "subreddits  = ['boston','losangeles','texas','mentalhealth','depression']\n",
        "periods     = [\"Jan'19\",\"Feb'19\",\"Mar'19\",\"Apr'19\",\"May'19\",\"Jun'19\",\"Jul'19\",\"Aug'19\",\"Sep'19\",\"Oct'19\",\"Nov'19\",\"Dec'19\",\n",
        "               \"Jan'20\",\"Feb'20\",\"Mar'20\",\"Apr'20\",\"May'20\",\"Jun'20\",\"Jul'20\",\"Aug'20\",\"Sep'20\",\"Oct'20\",\"Nov'20\",\"Dec'20\",\n",
        "               \"Jan'21\",\"Feb'21\",\"Mar'21\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKiMhlqYGwVS"
      },
      "source": [
        "dfs = {}\n",
        "for subreddit in subreddits:\n",
        "  dfs[subreddit] = pd.read_csv('{0}{1}_pred.csv'.format(project_dir,subreddit), encoding = 'utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WsHXOAAiIbjM",
        "outputId": "d3a67cc6-78b4-4963-8740-9670cba28379"
      },
      "source": [
        "dfs['boston'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>period</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>If he's telling the truth yes. But then how do...</td>\n",
              "      <td>1</td>\n",
              "      <td>boston</td>\n",
              "      <td>0.845337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Being a conductor on the commuter rail I alway...</td>\n",
              "      <td>1</td>\n",
              "      <td>boston</td>\n",
              "      <td>0.504415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>club hits like “police action” and “harvard si...</td>\n",
              "      <td>1</td>\n",
              "      <td>boston</td>\n",
              "      <td>0.945364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>This looks like a pretty big ruling for the ar...</td>\n",
              "      <td>1</td>\n",
              "      <td>boston</td>\n",
              "      <td>0.865318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Impressive..  keep up the good work!</td>\n",
              "      <td>1</td>\n",
              "      <td>boston</td>\n",
              "      <td>0.989395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   period  ... prediction\n",
              "0       0  ...   0.845337\n",
              "1       0  ...   0.504415\n",
              "2       0  ...   0.945364\n",
              "3       0  ...   0.865318\n",
              "4       0  ...   0.989395\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt310PQ1IkDX"
      },
      "source": [
        "stopwords = set(stopwords.words('english'))\n",
        "exclude   = set(string.punctuation)\n",
        "lemma     = WordNetLemmatizer()\n",
        "\n",
        "def clean(document):\n",
        "    stopwordremoval = \" \".join([i for i in document.lower().split() if i not in stopwords])\n",
        "    punctuationremoval = ''.join(ch for ch in stopwordremoval if ch not in exclude)\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punctuationremoval.split())\n",
        "    return normalized.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blDn3EWXI1Sa"
      },
      "source": [
        "df = dfs['mentalhealth'].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aorzCZdmJCS5"
      },
      "source": [
        "df['body'].fillna('', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuR3n0XpJytu"
      },
      "source": [
        "df['body'] = df.body.apply(clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kSG4EZVFKSZy",
        "outputId": "238a28a4-4a29-49a0-bb36-819414e0a243"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>period</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[differ, region, generally, psychiatrist, md, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>mentalhealth</td>\n",
              "      <td>0.664445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[it’s, trial, error, trying, find, one, like, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>mentalhealth</td>\n",
              "      <td>0.711806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>[isolating, bad, idea, isolated, try, reflect,...</td>\n",
              "      <td>1</td>\n",
              "      <td>mentalhealth</td>\n",
              "      <td>0.906247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>[inpatient, went, rehab, horrible, necessary, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>mentalhealth</td>\n",
              "      <td>0.046962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>[similar, problem, thinking, i’m, good, enough...</td>\n",
              "      <td>1</td>\n",
              "      <td>mentalhealth</td>\n",
              "      <td>0.741181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   period  ... prediction\n",
              "0       0  ...   0.664445\n",
              "1       0  ...   0.711806\n",
              "2       0  ...   0.906247\n",
              "3       0  ...   0.046962\n",
              "4       0  ...   0.741181\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEgi0mw1NEuq",
        "outputId": "0ea8ccf6-e681-4d04-98e2-769fb4f941a9"
      },
      "source": [
        "len(df[df['period'] == 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH8E86OoNHAj",
        "outputId": "fcc87da0-f045-410b-be25-2210961f2814"
      },
      "source": [
        "type((df[df['period'] == 0]['body'].values)[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clAu_g_vNuCs"
      },
      "source": [
        "Lda_object = gensim.models.ldamodel.LdaModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sDB7_feM0D4",
        "outputId": "c260b49a-85a4-4647-d757-ce6f292f264a"
      },
      "source": [
        "topics = []\n",
        "\n",
        "for period in range(len(periods)):\n",
        "  print(period)\n",
        "  curr_dic        = corpora.Dictionary(df[df['period'] == period]['body'].values)\n",
        "  curr_matrix     = [curr_dic.doc2bow(doc) for doc in list(df[df['period'] == period]['body'].values)]\n",
        "  curr_lda_model  = Lda_object(curr_matrix, num_topics=2, id2word = curr_dic)\n",
        "  topics.append(curr_lda_model.print_topics(num_topics=2, num_words=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orCPE1V-G06H",
        "outputId": "c8d2aee9-dc7c-4941-b6a8-976c6c7d1a32"
      },
      "source": [
        "topics[15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.014*\"like\" + 0.011*\"feel\" + 0.011*\"im\" + 0.010*\"thing\" + 0.009*\"time\"'),\n",
              " (1,\n",
              "  '0.013*\"help\" + 0.011*\"know\" + 0.009*\"you\" + 0.008*\"i’m\" + 0.008*\"people\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRHvL1bZI6ap",
        "outputId": "e0cd0c33-405e-43e0-da84-95325c20af8c"
      },
      "source": [
        "for i, item in enumerate(topics):\n",
        "  print(i + 1)\n",
        "  print(item)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "[(0, '0.013*\"like\" + 0.010*\"feel\" + 0.009*\"thing\" + 0.009*\"help\" + 0.009*\"people\"'), (1, '0.007*\"get\" + 0.006*\"one\" + 0.006*\"would\" + 0.005*\"im\" + 0.005*\"like\"')]\n",
            "2\n",
            "[(0, '0.015*\"like\" + 0.012*\"feel\" + 0.009*\"get\" + 0.009*\"know\" + 0.008*\"thing\"'), (1, '0.008*\"get\" + 0.007*\"help\" + 0.006*\"like\" + 0.006*\"im\" + 0.006*\"one\"')]\n",
            "3\n",
            "[(0, '0.011*\"feel\" + 0.011*\"im\" + 0.011*\"shit\" + 0.010*\"get\" + 0.010*\"like\"'), (1, '0.011*\"like\" + 0.008*\"i’m\" + 0.008*\"get\" + 0.007*\"help\" + 0.007*\"thing\"')]\n",
            "4\n",
            "[(0, '0.011*\"im\" + 0.009*\"like\" + 0.009*\"thing\" + 0.008*\"people\" + 0.007*\"know\"'), (1, '0.012*\"like\" + 0.011*\"help\" + 0.010*\"get\" + 0.010*\"feel\" + 0.008*\"people\"')]\n",
            "5\n",
            "[(0, '0.013*\"help\" + 0.012*\"im\" + 0.011*\"like\" + 0.009*\"thing\" + 0.008*\"know\"'), (1, '0.010*\"like\" + 0.008*\"get\" + 0.008*\"feel\" + 0.007*\"anxiety\" + 0.007*\"people\"')]\n",
            "6\n",
            "[(0, '0.013*\"im\" + 0.012*\"like\" + 0.009*\"people\" + 0.008*\"know\" + 0.008*\"time\"'), (1, '0.012*\"help\" + 0.010*\"like\" + 0.010*\"get\" + 0.009*\"feel\" + 0.009*\"thing\"')]\n",
            "7\n",
            "[(0, '0.011*\"like\" + 0.011*\"feel\" + 0.010*\"get\" + 0.010*\"thing\" + 0.010*\"know\"'), (1, '0.011*\"like\" + 0.008*\"people\" + 0.008*\"help\" + 0.007*\"mental\" + 0.006*\"also\"')]\n",
            "8\n",
            "[(0, '0.010*\"help\" + 0.010*\"like\" + 0.009*\"get\" + 0.009*\"feel\" + 0.008*\"know\"'), (1, '0.013*\"im\" + 0.013*\"like\" + 0.011*\"people\" + 0.008*\"get\" + 0.007*\"think\"')]\n",
            "9\n",
            "[(0, '0.016*\"like\" + 0.012*\"people\" + 0.012*\"im\" + 0.012*\"feel\" + 0.008*\"thing\"'), (1, '0.012*\"help\" + 0.011*\"get\" + 0.008*\"time\" + 0.008*\"know\" + 0.007*\"think\"')]\n",
            "10\n",
            "[(0, '0.011*\"help\" + 0.011*\"get\" + 0.009*\"im\" + 0.008*\"really\" + 0.008*\"you\"'), (1, '0.016*\"like\" + 0.012*\"feel\" + 0.009*\"people\" + 0.009*\"know\" + 0.008*\"thing\"')]\n",
            "11\n",
            "[(0, '0.010*\"you\" + 0.009*\"people\" + 0.009*\"i’m\" + 0.007*\"know\" + 0.007*\"thank\"'), (1, '0.014*\"like\" + 0.012*\"feel\" + 0.011*\"get\" + 0.010*\"help\" + 0.009*\"thing\"')]\n",
            "12\n",
            "[(0, '0.009*\"time\" + 0.009*\"get\" + 0.008*\"like\" + 0.007*\"one\" + 0.007*\"feel\"'), (1, '0.014*\"people\" + 0.013*\"like\" + 0.011*\"help\" + 0.010*\"feel\" + 0.010*\"really\"')]\n",
            "13\n",
            "[(0, '0.013*\"like\" + 0.012*\"feel\" + 0.010*\"people\" + 0.010*\"know\" + 0.010*\"help\"'), (1, '0.010*\"go\" + 0.009*\"like\" + 0.008*\"get\" + 0.008*\"time\" + 0.007*\"help\"')]\n",
            "14\n",
            "[(0, '0.013*\"help\" + 0.012*\"like\" + 0.010*\"go\" + 0.009*\"find\" + 0.008*\"thing\"'), (1, '0.010*\"like\" + 0.010*\"get\" + 0.010*\"feel\" + 0.008*\"im\" + 0.008*\"know\"')]\n",
            "15\n",
            "[(0, '0.014*\"im\" + 0.013*\"like\" + 0.012*\"help\" + 0.009*\"get\" + 0.008*\"know\"'), (1, '0.012*\"like\" + 0.010*\"thing\" + 0.010*\"feel\" + 0.009*\"people\" + 0.009*\"time\"')]\n",
            "16\n",
            "[(0, '0.014*\"like\" + 0.011*\"feel\" + 0.011*\"im\" + 0.010*\"thing\" + 0.009*\"time\"'), (1, '0.013*\"help\" + 0.011*\"know\" + 0.009*\"you\" + 0.008*\"i’m\" + 0.008*\"people\"')]\n",
            "17\n",
            "[(0, '0.016*\"help\" + 0.009*\"get\" + 0.007*\"someone\" + 0.007*\"find\" + 0.007*\"know\"'), (1, '0.014*\"like\" + 0.010*\"feel\" + 0.010*\"people\" + 0.009*\"im\" + 0.009*\"thing\"')]\n",
            "18\n",
            "[(0, '0.072*\"please\" + 0.034*\"post\" + 0.027*\"thank\" + 0.022*\"comment\" + 0.021*\"seeking\"'), (1, '0.011*\"like\" + 0.010*\"people\" + 0.008*\"know\" + 0.008*\"get\" + 0.008*\"feel\"')]\n",
            "19\n",
            "[(0, '0.012*\"like\" + 0.009*\"help\" + 0.009*\"feel\" + 0.008*\"people\" + 0.008*\"get\"'), (1, '0.081*\"please\" + 0.035*\"post\" + 0.024*\"thank\" + 0.023*\"comment\" + 0.023*\"list\"')]\n",
            "20\n",
            "[(0, '0.014*\"fuck\" + 0.012*\"like\" + 0.010*\"help\" + 0.009*\"feel\" + 0.008*\"get\"'), (1, '0.080*\"please\" + 0.036*\"post\" + 0.024*\"thank\" + 0.023*\"comment\" + 0.023*\"list\"')]\n",
            "21\n",
            "[(0, '0.011*\"like\" + 0.009*\"help\" + 0.009*\"get\" + 0.009*\"feel\" + 0.008*\"thing\"'), (1, '0.081*\"please\" + 0.035*\"post\" + 0.025*\"thank\" + 0.023*\"comment\" + 0.023*\"number\"')]\n",
            "22\n",
            "[(0, '0.081*\"please\" + 0.036*\"post\" + 0.024*\"thank\" + 0.023*\"comment\" + 0.023*\"seeking\"'), (1, '0.011*\"like\" + 0.010*\"help\" + 0.008*\"know\" + 0.008*\"feel\" + 0.008*\"people\"')]\n",
            "23\n",
            "[(0, '0.012*\"like\" + 0.010*\"help\" + 0.009*\"get\" + 0.008*\"know\" + 0.008*\"feel\"'), (1, '0.081*\"please\" + 0.036*\"post\" + 0.025*\"thank\" + 0.023*\"comment\" + 0.023*\"community\"')]\n",
            "24\n",
            "[(0, '0.080*\"please\" + 0.036*\"post\" + 0.024*\"thank\" + 0.023*\"comment\" + 0.023*\"list\"'), (1, '0.012*\"like\" + 0.009*\"help\" + 0.009*\"feel\" + 0.008*\"get\" + 0.008*\"know\"')]\n",
            "25\n",
            "[(0, '0.011*\"like\" + 0.009*\"help\" + 0.009*\"feel\" + 0.009*\"get\" + 0.008*\"people\"'), (1, '0.080*\"please\" + 0.035*\"post\" + 0.024*\"thank\" + 0.023*\"comment\" + 0.023*\"list\"')]\n",
            "26\n",
            "[(0, '0.080*\"please\" + 0.035*\"post\" + 0.024*\"thank\" + 0.023*\"comment\" + 0.023*\"list\"'), (1, '0.011*\"like\" + 0.009*\"help\" + 0.009*\"get\" + 0.008*\"thing\" + 0.008*\"feel\"')]\n",
            "27\n",
            "[(0, '0.079*\"please\" + 0.035*\"post\" + 0.024*\"thank\" + 0.023*\"comment\" + 0.023*\"list\"'), (1, '0.021*\"happy\" + 0.018*\"people\" + 0.016*\"someone\" + 0.015*\"ive\" + 0.015*\"cant\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}